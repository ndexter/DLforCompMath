{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to tensorflow\n",
    "\n",
    "This portion of the tutorial, we'll discuss basics of tensorflow in the context of some illustrative numerical examples.\n",
    "\n",
    "The first step is to import tensorflow and enable eager execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TensorFlow version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "tf.executing_eagerly()\n",
    "\n",
    "print('Loaded TensorFlow version ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After version 1.7, TensorFlow supports a new execution mode that is easier for use with the interactive python interpreter. Google describes its eager execution mode as \"an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later.\"\n",
    "\n",
    "TensorFlow used to only support creating a graph first and only evaluating operations in the context of \"sessions.\"\n",
    "\n",
    "For example (this code constructs a computational graph, but does not initialize variables until Session is started):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "dim1 = 1\n",
    "dim2 = 1\n",
    "sigma = 0.1\n",
    "precision = tf.float32\n",
    "rho = tf.nn.relu\n",
    "layers = 3\n",
    "\n",
    "# placeholders are not compatibe with TF's eager execution mode\n",
    "x = tf.placeholder(precision, shape = [dim1, None], name = 'input')\n",
    "\n",
    "with tf.variable_scope('Model'):\n",
    "\n",
    "    # input layer\n",
    "    in_W = tf.get_variable(name = 'in_W', shape = [dim2, dim1],\n",
    "            initializer = tf.random_normal_initializer(stddev = sigma, dtype = precision), \n",
    "            dtype = precision)\n",
    "\n",
    "    in_b = tf.get_variable(name = 'in_b', shape = [dim2, 1],\n",
    "            initializer = tf.random_normal_initializer(stddev = sigma, dtype = precision), \n",
    "            dtype = precision)\n",
    "    \n",
    "    x = rho(tf.matmul(in_W, x) + in_b)\n",
    "    \n",
    "    # build\n",
    "    for layer in range(layers):\n",
    "\n",
    "        W = tf.get_variable(name = 'l' + str(layer) + '_W', shape = [dim1, dim2],\n",
    "                initializer = tf.random_normal_initializer(stddev = sigma, dtype = precision), \n",
    "                dtype = precision)\n",
    "\n",
    "        b = tf.get_variable(name = 'l' + str(layer) + '_b', shape = [dim2, 1],\n",
    "                initializer = tf.random_normal_initializer(stddev = sigma, dtype = precision), \n",
    "                dtype = precision)\n",
    "    \n",
    "        x = rho(tf.matmul(W, x) + b)\n",
    "        \n",
    "    # output layer description\n",
    "    out_v = tf.get_variable(name = 'out_v', shape = [dim1, dim2],\n",
    "         initializer = tf.random_normal_initializer(stddev = sigma, dtype = precision), \n",
    "         dtype = precision)\n",
    "    \n",
    "    x = tf.matmul(out_v, x, name = 'output')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # variables such as weights and biases are not actually initialized until here\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic operations\n",
    "\n",
    "TF supports basic operations such as addition, squaring, matrix-vector products, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(b'aGVsbG8gd29ybGQ', shape=(), dtype=string)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.encode_base64(\"hello world\"))\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can determine the shape and data type of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is compatible with python's numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert numpy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "And NumPy operations convert Tensors to numpy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "The .numpy() method explicitly converts a Tensor to a numpy array\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try making a tensor with some data. First, we'll create a numpy array. Then we'll convert the numpy array into a TF tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  2.  3.]\n",
      "  [ 4.  5.  6.]]\n",
      "\n",
      " [[ 7.  8.  9.]\n",
      "  [10. 11. 12.]]\n",
      "\n",
      " [[13. 14. 15.]\n",
      "  [16. 17. 18.]]]\n",
      "\n",
      " x has shape: \n",
      "\n",
      "(3, 2, 3)\n",
      "\n",
      " x is now a \n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 1.  2.  3.]\n",
      "  [ 4.  5.  6.]]\n",
      "\n",
      " [[ 7.  8.  9.]\n",
      "  [10. 11. 12.]]\n",
      "\n",
      " [[13. 14. 15.]\n",
      "  [16. 17. 18.]]], shape=(3, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[[ 1.,  2.,  3.], [ 4.,  5.,  6.]],\n",
    "                   [[ 7.,  8.,  9.], [10., 11., 12.]],\n",
    "                   [[13., 14., 15.], [16., 17., 18.]]])\n",
    "\n",
    "print(x_data)\n",
    "\n",
    "print('\\n x has shape: \\n')\n",
    "\n",
    "print(np.shape(x_data))\n",
    "\n",
    "# now let's make a TF tensor from the data\n",
    "x = tf.convert_to_tensor(x_data, dtype = tf.float32)\n",
    "\n",
    "print('\\n x is now a \\n')\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation\n",
    "\n",
    "TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2, 2))\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    # take sum of elements of x\n",
    "    y = tf.reduce_sum(x)\n",
    "    print(y)\n",
    "    # multiply to get y^2\n",
    "    z = tf.multiply(y, y)\n",
    "    print(z)\n",
    "\n",
    "# Derivative of z with respect to the original input tensor x\n",
    "dz_dx = t.gradient(z, x)\n",
    "print(dz_dx)\n",
    "for i in [0, 1]:\n",
    "    for j in [0, 1]:\n",
    "        assert dz_dx[i][j].numpy() == 8.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also request gradients of the output with respect to intermediate values computed during a \"recorded\" tf.GradientTape context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2, 2))\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    # take sum of elements of x\n",
    "    y = tf.reduce_sum(x)\n",
    "    print(y)\n",
    "    # multiply to get y^2\n",
    "    z = tf.multiply(y, y)\n",
    "\n",
    "# Use the tape to compute the derivative of z with respect to the\n",
    "# intermediate value y.\n",
    "dz_dy = t.gradient(z, y)\n",
    "assert dz_dy.numpy() == 8.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing is a common operation performed on tensors. Let's try looking at a few slices of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing is performed from a start index to a finishing index.\n",
      "If I slice from (0,0,0) to (3,2,3), I obtain the entire tensor: \n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 1.  2.  3.]\n",
      "  [ 4.  5.  6.]]\n",
      "\n",
      " [[ 7.  8.  9.]\n",
      "  [10. 11. 12.]]\n",
      "\n",
      " [[13. 14. 15.]\n",
      "  [16. 17. 99.]]], shape=(3, 2, 3), dtype=float32)\n",
      "\n",
      " If I slice from (1,0,0) to (2,2,3), I obtain: \n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 7.  8.  9.]\n",
      "  [10. 11. 12.]]\n",
      "\n",
      " [[13. 14. 15.]\n",
      "  [16. 17. 99.]]], shape=(2, 2, 3), dtype=float32)\n",
      "\n",
      " If I slice from (2,0,0) to (3,2,3), I obtain: \n",
      "\n",
      "tf.Tensor(\n",
      "[[[13. 14. 15.]\n",
      "  [16. 17. 99.]]], shape=(1, 2, 3), dtype=float32)\n",
      "\n",
      " If I slice from (0,1,0) to (3,2,3), I obtain: \n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 4.  5.  6.]]\n",
      "\n",
      " [[10. 11. 12.]]\n",
      "\n",
      " [[16. 17. 99.]]], shape=(3, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 2.]\n",
      "  [ 5.]]\n",
      "\n",
      " [[ 8.]\n",
      "  [11.]]\n",
      "\n",
      " [[14.]\n",
      "  [17.]]], shape=(3, 2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 2.  3.]\n",
      "  [ 5.  6.]]\n",
      "\n",
      " [[ 8.  9.]\n",
      "  [11. 12.]]\n",
      "\n",
      " [[14. 15.]\n",
      "  [17. 99.]]], shape=(3, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Slicing is performed from a start index to a finishing index.')\n",
    "print('If I slice from (0,0,0) to (3,2,3), I obtain the entire tensor: \\n')\n",
    "print(tf.slice(x,[0,0,0],[3,2,3])) # the whole tensor\n",
    "\n",
    "print('\\n If I slice from (1,0,0) to (2,2,3), I obtain: \\n')\n",
    "print(tf.slice(x,[1,0,0],[2,2,3]))\n",
    "\n",
    "print('\\n If I slice from (2,0,0) to (3,2,3), I obtain: \\n')\n",
    "print(tf.slice(x,[2,0,0],[1,2,3]))\n",
    "\n",
    "print('\\n If I slice from (0,1,0) to (3,2,3), I obtain: \\n')\n",
    "print(tf.slice(x,[0,1,0],[3,1,3]))\n",
    "print(tf.slice(x,[0,0,1],[3,2,1]))\n",
    "print(tf.slice(x,[0,0,1],[3,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
